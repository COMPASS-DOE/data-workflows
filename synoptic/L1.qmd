---
title: "L1"
author: "COMPASS workflows team"
title-block-banner: true
params:
  html_outfile: "L1.html"
  DATA_ROOT: "data_TEST/"
  L1_NORMALIZE: "L1_normalize/"
  L1: "L1/"
  L1_METADATA: "L1_metadata/"
  debug: false
  remove_input_files: false
  write_plots: true
  logfile: ""
date: now
date-format: "YYYY-MM-DD HH:mm:ssZ"
format: 
  html:
    code-fold: true
editor: visual
---

This script

-   Reads in all the L1_normalize files

-   Compiles and writes them out into separate <year><month><site> files

## Initializing

```{r init}
#| include: false

library(ggplot2)
theme_set(theme_bw())
library(compasstools)
if(packageVersion("compasstools") < "0.2") {
    stop("Please update to latest version of compasstools!\n",
         "devtools::install_github('COMPASS-DOE/compasstools')")
}

source("helpers.R")

# Open the fLag database
source("flag-database.R")
fdb_open(params$DATA_ROOT, init = TRUE)

L1_NORMALIZE <- file.path(params$DATA_ROOT, params$L1_NORMALIZE)
dirs_to_process <- scan_folders(L1_NORMALIZE)

L1 <- file.path(params$DATA_ROOT, params$L1)

```

I see `r length(dirs_to_process)` directories to process in `r L1_NORMALIZE`.

Output directory is `r L1`.

HTML outfile is "`r params$html_outfile`".

## Processing

```{r processing}
f <- function(dir_name, dirs_to_process, out_dir) {
    message(Sys.time(), " Processing ", basename(dir_name))
    d <- dirs_to_process[[dir_name]]
    message("\tIt has ", length(d), " files")
    
    # Read all files in a folder
    # Note that we're forcing `value` and `value_raw` to be character, so that
    # everything can be stacked into a single data frame
    dat_raw <- read_csv_group(d,
                              remove_input_files = params$remove_input_files, 
                              col_types = "cccccTdcccdii")

    # File-based summary
    message("\tTotal data: ", nrow(dat_raw), " rows, ", ncol(dat_raw), " columns")
    smry <- data.frame(Dir = dir_name, 
                       Files = length(d), 
                       Rows = nrow(dat_raw))
    
    # Remove duplicate rows (e.g. from multiple datalogger downloads)
    dat <- dat_raw[!duplicated(dat_raw), ]
    message("\tRemoved ", nrow(dat_raw) - nrow(dat), " duplicate rows")
    
    # Make sure Plot (if present) and TIMESTAMP columns are on the left
    lefts <- intersect(c("Plot", "TIMESTAMP"), colnames(dat))
    rights <- setdiff(colnames(dat), lefts)
    dat <- dat[c(lefts, rights)]
    # Remove unneeded columns if present
    site <- dat$Site[1]
    dat <- dat[setdiff(colnames(dat), 
                       c("Site", "Logger", "Table",
                         "value_raw", "units", "loggernet_variable"))]
    # And finally, sort
    dat <- dat[order(dat$TIMESTAMP, dat$design_link),]
    
    write_to_folders(dat, 
                     root_dir = out_dir, 
                     data_level = "L1",
                     site = site,
                     write_plots = params$write_plots)
    
    # Add any OOB flags to the flag database
    flg <- dat[!is.na(dat$F_OOB) & dat$F_OOB == 1, "ID"]
    if(nrow(flg)) {
        flg$Flag_type <- "OOB"
        flg$Remark <- basename(dir_name)
        message("Sending ", nrow(flg), " flags to database")
        fdb_add_flags(site, flg)
    }
    
    return(smry)
}

log_info("About to L1", logfile = params$logfile)
tryCatch({
out <- lapply(names(dirs_to_process), f, 
              dirs_to_process = dirs_to_process, out_dir = L1)
},
error = function(e) {
    log_warning("L1: an error occurred!", logfile = params$logfile)
    log_info(as.character(e), logfile = params$logfile)
    stop(e)
})
```

## Metadata

L1 metadata template directory is `r params$L1_METADATA`.

```{r metadata}

# Get the L1 template file
template_file <- file.path(params$DATA_ROOT,
                           params$L1_METADATA, 
                           "L1_metadata_template.txt")
if(!file.exists(template_file)) {
    stop("Couldn't find file ", basenme(template_file), " in ", params$L1_METADATA)
}
L1_metadata_template <- readLines(template_file)

# Get the column metadata file
col_md <- read.csv(file.path(params$DATA_ROOT,
                             params$L1_METADATA,
                             "L1_metadata_columns.csv"))
col_md_for_insert <- paste(sprintf("%-15s", col_md$Column), col_md$Description)

# Get the variable metadata
var_md <- read.csv(file.path(params$DATA_ROOT,
                             params$L1_METADATA,
                             "L1_metadata_vars.csv"))
var_md_for_insert <- paste(sprintf("%-20s", c("research_name", var_md$research_name)),
                           sprintf("%-12s", c("Sensor", var_md$sensor)),
                           sprintf("%-10s", c("Units", var_md$final_units)),
                           sprintf("%-12s", c("Bounds", paste0(var_md$low_bound, ", ", var_md$high_bound))),
                           c("Description", var_md$description))

message("Main template has ", length(L1_metadata_template), " lines")
message("Column metadata info has ", length(col_md_for_insert), " lines")
message("Variable metadata info has ", length(var_md_for_insert), " lines")

# Identify the main data directories in L1/, which are <site>_<year>
data_dirs <- list.files(file.path(params$DATA_ROOT, params$L1), 
                        pattern = "^[a-zA-Z]+_[0-4]{4}$")

for(dd in data_dirs) {
    dd_full <- file.path(params$DATA_ROOT, params$L1, dd)
    message("Generating metadata for ", dd_full)
    
    message("\tInserting timestamp and folder name")
    md <- gsub("[TIMESTAMP]", date(), L1_metadata_template, fixed = TRUE)
    md <- gsub("[FOLDER_NAME]", dd, md, fixed = TRUE)
    
    # File info
    files <- list.files(path = dd_full, pattern = "csv$", full.names = TRUE)
    message("\tFound ", length(files), " data files")
    file_info <- c()
    # Build up information about files...
    for(f in files) {
        # Ensure that the file headers match our column metadata
        file_headers <- colnames(read.csv(f, nrows = 0))
        if(!identical(sort(col_md$Column), sort(file_headers))) {
            stop("File ", basename(f), 
                 " headers don't match column metadata.",
                 "\nColumns in metadata but not in data: ",
                 paste(setdiff(col_md$Column, file_headers), collapse = ", "),
                 "\nColumns in data but not in metdata: ",
                 paste(setdiff(file_headers, col_md$Column), collapse = ", "))
        }
        fdata <- readLines(f) # just for a quick line count
        file_info <- c(file_info, 
                       basename(f),
                       paste("Rows:", length(fdata) - 1),
                       paste("md5:", digest::digest(f, file = TRUE)),
                       "")
    }
    # ...and insert into metadata
    # We used the head(-1) to drop the final empty line, just to keep things pretty
    file_info_pos <- grep("[FILE_INFO", md, fixed = TRUE)
    md <- append(md, head(file_info, -1), after = file_info_pos)
    md <- md[-file_info_pos]
    
    # Insert column metadata
    col_info_pos <- grep("[COLUMN_INFO]", md, fixed = TRUE)
    md <- append(md, col_md_for_insert, after = col_info_pos)
    md <- md[-col_info_pos]
    # The NA code is an in-line replacement
    md <- gsub("[NA_STRING_L1]", NA_STRING_L1, md, fixed = TRUE)

    # Insert variable metadata
    var_info_pos <- grep("[VARIABLE_INFO]", md, fixed = TRUE)
    md <- append(md, var_md_for_insert, after = var_info_pos)
    md <- md[-var_info_pos]
    
    # Site information
    # Folders are <site>_<year>
    # There MUST be a informational file named <site>.txt
    site <- strsplit(dd, "_")[[1]][1]
    site_md_file <- file.path(params$DATA_ROOT, params$L1_METADATA, paste0(site, ".txt"))
    if(!file.exists(site_md_file)) {
        stop("Couldn't find file ", site_md_file, " in ", params$L1_METADATA)
    }
    message("\tFound ", basename(site_md_file))
    site_md_for_insert <- readLines(site_md_file)

    # Insert site information    
    site_info_pos <- grep("[SITE_INFO]", md, fixed = TRUE)
    md <- append(md, site_md_for_insert, after = site_info_pos)
    md <- md[-site_info_pos]

    # Write the final metadata file
    mdfn <- paste0(dd, "_metadata.txt")
    message("\tWriting ", mdfn, "...")
    writeLines(md, file.path(params$DATA_ROOT, params$L1, dd, mdfn))
}
```

## Output summary

```{r output_summary_table}
out_df <- do.call("rbind", out)
knitr::kable(out_df)
```

## Clean up

```{r cleanup}
fdb_cleanup() # Close flags database
```

## Reproducibility

Git commit `r GIT_COMMIT`.

```{r reproducibility}
sessionInfo()
```
