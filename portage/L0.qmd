---
title: "Workflow: L0"
author: "COMPASS workflows team"
title-block-banner: true
params:
  html_outfile: "L0.html"
  raw: "data_TEST/Raw/"
  remove_input_files: false
  raw_done: "data_TEST/Raw_done/"
  L0: "data_TEST/L0/"
  logfile: ""
date: now
date-format: "YYYY-MM-DD HH:mm:ssZ"
format: 
  html:
    code-fold: true
editor: visual
---

This script

-   Reads in the raw data files one by one

-   Extracts `Logger` and `Table` information from the header and adds them as columns

-   Writes as CSV files with row/col/hash info in filename

-   Moves the raw files to a Raw_done folder

## Initializing

```{r}
#| include: false

library(compasstools)
if(!exists("read_datalogger_file")) {
    stop("Please update to latest version of compasstools!\n",
         "devtools::install_github('COMPASS-DOE/compasstools')")
}
library(readr)
files_to_process <- list.files(params$raw, pattern = "*.dat$", 
                               full.names = TRUE, recursive = TRUE)

source("helpers.R")
```

I see `r length(files_to_process)` files to process.

Writing to `r normalizePath(params$L0)`.

HTML outfile is `r params$html_outfile`.

Logfile is `r params$logfile`.

Working directory is `r getwd()`.

## Processing

```{r}
overwrites <- 0
errors <- 0

f <- function(fn, new_dir) {
    basefn <- basename(fn)
    message(Sys.time(), " Processing ", basefn)
    # Try to read in the data; if it doesn't work, we won't get a data frame back
    dat <- try(compasstools::read_datalogger_file(fn))
    if(is.data.frame(dat)) {
        # Construct the new filename: old filename + nrow + ncol + hash
        # This is so we can distinguish datasets with identical raw filename but
        # differing data contents (can happen sometimes with dataloggers)
        stripped_fn <- gsub("\\.dat$", "", basefn)
        short_hash <- substr(digest::digest(dat), 1, 6)
        new_fn <- paste0(stripped_fn, "_", nrow(dat), "x", ncol(dat), "_", short_hash, ".csv")
        
        note <- ""
        message("\tWriting ", new_fn)
        if(file.exists(file.path(new_dir, new_fn))) {
            note <- "Overwriting existing file"
            message(paste0("\t", note))
            overwrites <<- overwrites + 1
        }
        
        # Write the new file, checking to make sure successful
        new_fqfn <- file.path(new_dir, new_fn)
        try(write.csv(dat, new_fqfn, row.names = FALSE))
        if(!file.exists(new_fqfn)) {
            note <- "Write error"
            message(paste0("\t", note))
            errors <<- errors + 1
       } else {
            # Move to 'Raw_done' folder
            if(params$remove_input_files) {
                file.copy(fn, file.path(params$raw_done, basefn), overwrite = FALSE)
                file.remove(fn)
            }
        }
    } else {
        note <- "Read error"
        message(paste0("\t", note))
        errors <<- errors + 1
    }
    # Return an informational data frame about file processed, dimensions, etc.
    data.frame(File = basefn,
               Logger = dat$Logger[1],
               Table = dat$Table[1],
               Rows = nrow(dat),
               Columns = ncol(dat),
               Hash = short_hash,
               Note = note)
}

out <- lapply(files_to_process, f, new_dir = params$L0)
```

## Summary

```{r}
#| echo: false
#| output: asis
if(overwrites) {
    cat("#### NOTE: ", overwrites, " file overwrite(s)\n")
    log_warning(paste("File overwrite(s)", params$html_outfile), 
                logfile = params$logfile)
}
if(errors) {
    cat("#### WARNING: ", errors, " file read/write error(s)\n")
    log_warning(paste("File read/write error(s)", params$html_outfile), 
                logfile = params$logfile)
}
```

```{r}
out_df <- do.call("rbind", out)
knitr::kable(out_df)
```

## Reproducibility

```{r}
sessionInfo()
```
