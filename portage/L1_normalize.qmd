---
title: "L1_normalize"
author: "COMPASS workflows team"
title-block-banner: true
params:
  L0: "data_TEST/L0/"
  REMOVE_INPUT_FILES: false
  html_outfile: "L1_normalize.html"
  L1_normalize: "data_TEST/L1_normalize/"
  design_table: "data_TEST/design_table.csv"
  units_table: "data_TEST/units_table.csv"
  bounds_table: "data_TEST/bounds_table.csv"
  logfile: ""
date: now
date-format: "YYYY-MM-DD HH:mm:ssZ"
format: 
  html:
    code-fold: true
editor: visual
---

This script

-   Reads in the L0 files one by one

-   Reshapes from wide to long; only `Logger`, `Table`, and `TIMESTAMP` don't get reshaped

-   Joins with the design table, adding `Site`, `design_link`, and `research_name` columns (every loggernet variable must have an entry)

-   Performs unit conversion (every research\_ name must have an entry)

-   Performs bounds checking (adding flags) for each \`research_name\` variable

-   Writes into \<year\>\_*\<*month*\>*\_\<site\> folders

## Initializing

```{r init}
#| include: false

library(tidyr)
library(dplyr)
library(readr)
library(compasstools)
if(!exists("expand_df")) {
    stop("Please update to latest version of compasstools!\n",
         "devtools::install_github('COMPASS-DOE/compasstools')")
}
dt <- read_csv(params$design_table, col_types = "cccccc")
# For compactness, the design table may have expansions. For example,
# "DiffVoltA_Avg({1:8})" -> "DiffVoltA_Avg(1)", "DiffVoltA_Avg(2)", etc., with
# extra rows added as needed:
dt_ex <- compasstools::expand_df(dt)

# Read the unit table (everything must have an entry)
ut <- read_csv(params$units_table, col_types = "ccccccc")
ut <- filter(ut, !is.na(research_name))

# Read the bounds table (not everything needs an entry)
read_csv(params$bounds_table, col_types = "cccccc") %>% 
    filter(!is.na(research_name), !is.na(units)) %>% 
    select(research_name, units, low, high) %>% 
    mutate(low = as.numeric(low), high = as.numeric(high)) ->
    bt

files_to_process <- list.files(params$L0, pattern = "*.csv$", full.names = TRUE)

source("helpers.R")
```

I see `r length(files_to_process)` files to process.

Design table is `r nrow(dt)` rows, `r nrow(dt_ex)` after expansion.

Units table is "`r params$units_table`" and has `r nrow(ut)` rows with conversion strings.

Bounds table is "`r params$bounds_table`" and has `r nrow(bt)` rows with bounds.

HTML outfile is "`r params$html_outfile`".

## Processing

```{r processing}
overwrites <- 0
errors <- 0

f <- function(fn, out_dir, design_table) {
    message(Sys.time(), " Processing ", basename(fn))

    smry <- data.frame(File = basename(fn), 
                       Pivoted_rows = NA_integer_,
                       dl_NA = NA_integer_,
                       Note = "")
    dat <- try(read_csv(fn, 
                    # don't want timestamp parsed to a datetime at this point
                    col_types = list(TIMESTAMP = col_character())))
    if(!is.data.frame(dat)) {
        smry$Note <- "Read error" 
        message("\t", Note)
        errors <<- errors + 1
        return(smry)
    }
    
    # ------------- Reshape to long form

    dat_long <- pivot_longer(dat, c(-Logger, -Table, -TIMESTAMP),
                             names_to = "loggernet_variable",
                             values_to = "value",
                             # We're stacking both numeric and character columns, 
                             # so force everything to character (no precision 
                             # loss since data came from a text file anyway)
                             values_transform = as.character)
    message("\tPivoted data has ", nrow(dat_long), " rows")
    smry$Pivoted_rows <- nrow(dat_long)

    # ------------- Design table

    # Check for missing entries in the design table
    dat_long %>% 
        anti_join(design_table,
                          by = c("Logger", "Table", "loggernet_variable")) %>% 
        select(Logger, Table, loggernet_variable) %>% 
        distinct() ->
        missings
    
    if(nrow(missings)) {
        message("\tERROR: missing design links: ", 
                paste(missings$loggernet_variable, collapse = ", "))
        smry$Note <- "Missing design link" 
        errors <<- errors + 1
        return(smry)
    }
    
    # Join with design table
    dat_long <- left_join(dat_long, design_table,
                          by = c("Logger", "Table", "loggernet_variable"),
                          relationship = "many-to-one")
    
    # Check for missing entries in the design table
    dat_long %>% 
        anti_join(design_table,
                          by = c("Logger", "Table", "loggernet_variable")) %>% 
        select(Logger, Table, loggernet_variable) %>% 
        distinct() ->
        missings
    
    if(nrow(missings)) {
        message("\tERROR: missing design links: ", paste(missings$loggernet_variable, collapse = ", "))
        smry$Note <- "Design link error" 
        errors <<- errors + 1
        return(smry)
    }

    # Summary information
    smry$dl_NA <- sum(is.na(dat_long$design_link))
    message("\tFiltering out ", smry$dl_NA, " empty design_link rows")
    dat_long <- filter(dat_long, !is.na(design_link))

    # ------------- Unit conversion
    
    # Check for missing entries in the units table
    rns <- unique(dat_long$research_name)
    missings <- rns[!rns %in% ut$research_name]
    if(length(missings)) {
        message("\tERROR: missing units entries: ", paste(missings, collapse = ", "))
        smry$Note <- "Missing unit entries" 
        errors <<- errors + 1
        return(smry)
    }

    message("\tDoing unit conversion")
    # At this point everything in the value column should be numeric
    dat_long$value <- as.numeric(dat_long$value)
    dat_long <- compasstools::unit_conversion(dat_long, ut)
    dat_long <- rename(dat_long, value_raw = value, value = value_conv)
    dat_long$value_conv <- NULL
    
    # ------------- Out-of-bounds flags

    message("\tAdding OOB flags")
    dat_long %>% 
        left_join(bt, by = c("research_name", "units")) %>% 
        mutate(OOB = value < low | value > high) %>% 
        select(-low, -high) ->
        dat_long
   
    write_to_folders(dat_long, root_dir = out_dir, 
                     data_level = "L1_normalize",
                     site = dat_long$Site[1], 
                     logger = dat_long$Logger[1],
                     table = dat_long$Table[1])

    if(params$REMOVE_INPUT_FILES) file.remove(fn)
    
    return(smry)
}

out <- lapply(files_to_process, f, 
              out_dir = params$L1_normalize,
              design_table = dt_ex)
```

## Summary

```{r summary}
#| echo: false
#| output: asis
if(overwrites) {
    cat("### WARNING: ", overwrites, " file overwrite(s)\n")
    log_warning(paste("File overwrite(s)", params$html_outfile), 
                logfile = params$logfile)
}
if(errors) {
    cat("### ERROR: ", errors, " error(s)\n")
    log_warning(paste("File read/write or processing error(s)", params$html_outfile), 
                logfile = params$logfile)
}
```

```{r summary_table}
out_df <- do.call("rbind", out)
knitr::kable(out_df)
```

## Reproducibility

```{r reproducibility}
sessionInfo()
```
