---
title: "L1a"
author: "COMPASS workflows team"
title-block-banner: true
params:
  html_outfile: "L1a.html"
  DATA_ROOT: "data_TEST/"
  L1_NORMALIZE: "L1_normalize/"
  L1A: "L1a/"
  OUTPUT_TEMPLATES: "L1a_output_templates/"
  NEWVARS_TABLE: "newvars_table.csv"
  remove_input_files: false
  logfile: ""
date: now
date-format: "YYYY-MM-DD HH:mm:ssZ"
format: 
  html:
    code-fold: true
editor: visual
---

This script

-   Reads in all the L1_normalize files by year/month/site

-   Rounds timestsamps

-   Computes new variables: `sapflow_avg` (a test)

-   Joins with plot table

## Initializing

```{r init}
#| include: false

library(tidyr)
library(dplyr)
library(readr)
library(lubridate)
library(compasstools)
if(!exists("scan_folders") | !exists("unit_conversion")) {
    stop("Please update to latest version of compasstools!\n",
         "devtools::install_github('COMPASS-DOE/compasstools')")
}

# The template tables in $OUTPUT_TEMPLATES are 'plot tables' in RR's terminology
# Read them into a list
ot <- list.files(file.path(params$DATA_ROOT, params$OUTPUT_TEMPLATES),
                 pattern = "*.csv$", full.names = TRUE)
templates <- lapply(ot, read_csv, show_col_types = FALSE)
names(templates) <- gsub("\\.csv", "", basename(ot))
# For compactness, plot tables may have expansions
templates <- lapply(templates, compasstools::expand_df)

# Read new variables table
NEWVARS_TABLE <- file.path(params$DATA_ROOT, params$NEWVARS_TABLE)
nvt <- read_csv(NEWVARS_TABLE, col_types = "cc")

source("helpers.R")

L1_NORMALIZE <- file.path(params$DATA_ROOT, params$L1_NORMALIZE)
dirs_to_process <- scan_folders(L1_NORMALIZE)

L1A <- file.path(params$DATA_ROOT, params$L1A)

```

I see `r length(dirs_to_process)` directories to process in `r L1_NORMALIZE`.

Output directory is `r L1A`.

Output table templates are in `r params$OUTPUT_TEMPLATES`; there are `r length(templates)` of them.

New variables table "`r NEWVARS_TABLE`" has `r nrow(nvt)` rows.

HTML outfile is "`r params$html_outfile`".

## Processing

```{r newvar_code}
#| include: false

# This chunk holds dedicated functions to compute new variables
# These must be named "NEWVAR_[new_research_name]", where "new_research_name"
# is given in the `newvars_table` CSV file
# Functions are given a data frame that is guaranteed to have needed variables
# (research names) as defined in the `newvars_table` CSV file
# Functions must return the data frame they're given, with "value" and "units" 
# columns added (optionally, also a "OOB" column)

# Compute sapflow_avg, the average of shallow and deep sapflow values
NEWVAR_sapflow_avg <- function(x) {
    x$value <- (x$sapflow + x$sapflow_deep) / 2.0
    x$units <- "??"
    return(x)
}
```

```{r processing}
overwrites <- 0
errors <- 0
dat_issues <- 0
file_read_smry <- data.frame()

f <- function(dir_name, dirs_to_process, out_dir) {
    message(Sys.time(), " Processing ", basename(dir_name))
    message("\tIt has ", length(dirs_to_process[[dir_name]]), " files")
    
    dat_raw <- read_csv_group(dirs_to_process[[dir_name]],
                              remove_input_files = params$remove_input_files, 
                              col_types = "ccTcdcccdcl")
    errors <<- errors + attr(dat_raw, "errors")
    
    # File-based summary
    message("\tTotal data: ", nrow(dat_raw), " rows, ", ncol(dat_raw), " columns")
    smry <- data.frame(Dir = dir_name, Files = length(dirs_to_process[[dir_name]]), 
                       Rows = nrow(dat_raw), Note = "")
    file_read_smry <<- rbind(file_read_smry, smry)
    
    # Remove duplicate rows (e.g. from multiple datalogger downloads)
    dat <- distinct(dat_raw)
    message("\tRemoved ", nrow(dat_raw) - nrow(dat), " duplicate rows")    

    # Go through the output tables one by one
    
    # Join plot table with data
    message("\tJoining with plot table")
    pt_ex %>% 
        left_join(dat, by = c("Site", "design_link"), 
                  relationship = "many-to-many") %>% 
        select(-Table, -loggernet_variable) ->
        dat_mrg
    
    missing <- anti_join(pt_ex, dat, by = c("Site", "design_link"))
    if(nrow(missing)) {
        dat_issues <<- dat_issues + 1
        message("ERROR: some design links in plot table not found: ", 
                paste(missing$design_link, collapse = ", "))
        smry$Note <- "Missing design_link(s)"
        return(smry)
    }
    
    # Compute new (derived) variables
    message("\tComputing derived variables")
    for(i in seq_len(nrow(nvt))) {
        new_rn <- nvt$new_research_name[i]
        rn_needed <- strsplit(nvt$needs_research_names[i], ",", fixed = TRUE)[[1]]
        # Isolate needed data and site/plot/tree/timestamp
        dat_mrg %>% 
            filter(research_name %in% rn_needed) %>% 
            select(Site, Plot, Tree, TIMESTAMP, research_name, value) %>% 
            pivot_wider(names_from = "research_name", values_from = "value") ->
            dat_subset
        
        message("\t\t", new_rn, " <- ", nvt$needs_research_names[i],
                " (using ", nrow(dat_subset), " rows)")
        
        # Call the computation function based on the name of the new variable
        # New variable functions MUST add "value" and "units" columns; optionally "OOB"
        dat_subset <- do.call(paste0("NEWVAR_", new_rn), list(dat_subset))
        # Clean up: add research_name...
        dat_subset$research_name <- new_rn
        # remove old research name columns (from the pivot_wider above)
        dat_subset[rn_needed] <- NULL
        # ...and add information entries in the design_link and Logger columns 
        if("design_link" %in% names(dat_mrg)) dat_subset$design_link <- "<derived>"
        if("Logger" %in% names(dat_mrg)) dat_subset$Logger <- "<derived>"
        # This is inefficient but assuming we won't have many
        # Also, new variables might be needed by further ones?!?
        dat_mrg <- bind_rows(dat_mrg, dat_subset)
    }
    
    # Plot table-based summary
    dat_mrg %>% 
        group_by(Site, Plot) %>% 
        summarise(TS_min = min(TIMESTAMP), 
                  TS_max = max(TIMESTAMP), 
                  Vars = length(unique(research_name)),
                  OOB = sum(OOB, na.rm = TRUE),
                  .groups = "drop") %>% 
        mutate(Dir = basename(dir_name), 
               Note = "") %>%
        select(Dir, Site, Plot, Vars, OOB, TS_min, TS_max, Note) ->
        smry
    
    # Error check
    # There should be only one research_name for each timestamp/site/plot/tree
    dat_mrg %>% 
        group_by(TIMESTAMP, Site, Plot, Tree, research_name) %>% 
        summarise(n = n(), .groups = "drop") %>% 
        filter(n > 1) %>% 
        mutate(Dir = basename(dir_name)) ->
        dat_mrg_problems
    
    if(nrow(dat_mrg_problems)) {
        dat_issues <<- dat_issues + 1
        message("There are duplicate research_names associated with each site/plot/tree")
        dat_mrg_problems$TIMESTAMP <- NULL
        print(distinct(dat_mrg_problems))
        smry$Note <- "Problems!"
    }
    
    # Put columns in Site, Plot, Tree, TIMESTAMP, research_name, value,
    # and then <others alphabetized> order
    lefts <- c("Site", "Plot", "Tree", "TIMESTAMP", "research_name", "value")
    dat_mrg <- dat_mrg[c(lefts, sort(setdiff(names(dat_mrg), lefts)))]
    
    write_to_folders(dat_mrg, root_dir = out_dir, data_level = "L1a",
                     site = dat$Site[1], logger = dat$Logger[1], table = "")
    
    return(smry)
}

out <- lapply(names(dirs_to_process), f, 
              dirs_to_process = dirs_to_process, out_dir = L1A)
```

## File summary

```{r summary}
#| echo: false
#| output: asis
if(overwrites) {
    cat("### WARNING: ", overwrites, " file overwrite(s)\n")
    log_warning(paste("File overwrite(s)", params$html_outfile), 
                logfile = params$logfile)
}
if(errors) {
    cat("### WARNING: ", errors, " file read/write error(s)\n")
    log_warning(paste("File read/write error(s)", params$html_outfile), 
                logfile = params$logfile)
}
if(dat_issues) {
    cat("### WARNING: ", dat_issues, " data structure issue(s)\n")
    log_warning(paste("data structure issue(s)", params$html_outfile), 
                logfile = params$logfile)
}
```

```{r file_summary_table}
knitr::kable(file_read_smry)
```

## Plot summary:

```{r plot_summary_table}
out_df <- do.call("rbind", out)
knitr::kable(out_df)
```

## Reproducibility

```{r reproducibility}
sessionInfo()
```
