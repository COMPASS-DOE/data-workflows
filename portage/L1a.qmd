---
title: "L1a"
author: "COMPASS workflows team"
title-block-banner: true
params:
  html_outfile: "L1a.html"
  DATA_ROOT: "data_TEST/"
  L1_NORMALIZE: "L1_normalize/"
  L1A: "L1a/"
  OUTPUT_TEMPLATES: "L1a_output_templates/"
  NEWVARS_TABLE: "newvars_table.csv"
  debug: false
  remove_input_files: false
  logfile: ""
date: now
date-format: "YYYY-MM-DD HH:mm:ssZ"
format: 
  html:
    code-fold: true
editor: visual
---

This script

-   Reads in all the L1_normalize files by year/month/site

-   Computes new variables: `sapflow_avg` (a test)

-   Loads all template tables and generates L1a output tables from them

## Initializing

```{r init}
#| include: false

library(tidyr)
library(dplyr)
library(readr)
library(lubridate)
library(compasstools)
if(!exists("scan_folders") | !exists("unit_conversion")) {
    stop("Please update to latest version of compasstools!\n",
         "devtools::install_github('COMPASS-DOE/compasstools')")
}

# The template tables in $OUTPUT_TEMPLATES are 'plot tables' in RR's terminology
# Read them into a list
ot <- list.files(file.path(params$DATA_ROOT, params$OUTPUT_TEMPLATES),
                 pattern = "*.csv$", full.names = TRUE)
templates <- lapply(ot, read_csv, show_col_types = FALSE)
names(templates) <- gsub("\\.csv", "", basename(ot))
# For compactness, plot tables may have expansions
templates <- lapply(templates, compasstools::expand_df)

# Read new variables table
NEWVARS_TABLE <- file.path(params$DATA_ROOT, params$NEWVARS_TABLE)
nvt <- read_csv(NEWVARS_TABLE, col_types = "cc")

source("helpers.R")

L1_NORMALIZE <- file.path(params$DATA_ROOT, params$L1_NORMALIZE)
dirs_to_process <- scan_folders(L1_NORMALIZE)

L1A <- file.path(params$DATA_ROOT, params$L1A)

```

I see `r length(dirs_to_process)` directories to process in `r L1_NORMALIZE`.

Output directory is `r L1A`.

Output table templates are in `r params$OUTPUT_TEMPLATES`; there are `r length(templates)` of them.

HTML outfile is "`r params$html_outfile`".

## Processing

```{r processing}
errors <- 0
dat_issues <- 0
file_read_smry <- data.frame()

f <- function(dir_name, dirs_to_process, out_dir) {
    message(Sys.time(), " Processing ", basename(dir_name))
    d <- dirs_to_process[[dir_name]]
    message("\tIt has ", length(d), " files")
    
    dat_raw <- read_csv_group(d,
                              remove_input_files = params$remove_input_files, 
                              col_types = "ccTcdcccdcl")
    errors <<- errors + attr(dat_raw, "errors")
    
    # File-based summary
    message("\tTotal data: ", nrow(dat_raw), " rows, ", ncol(dat_raw), " columns")
    file_read_smry <<- rbind(file_read_smry,
                             data.frame(Dir = dir_name, 
                                        Files = length(d), 
                                        Rows = nrow(dat_raw)))
    
    # Remove duplicate rows (e.g. from multiple datalogger downloads)
    dat <- distinct(dat_raw)
    message("\tRemoved ", nrow(dat_raw) - nrow(dat), " duplicate rows")    
    
    # Go through the output templates to generate output tables
    smry_all <- list()
    for(template in names(templates)) {
        pt_ex <- templates[[template]] # the expanded 'plot table'
        
        # Join plot table with data
        message("\t------------------------------------------------")
        message("\tJoining with output template (plot table) ", template)
        dat_mrg <- left_join(pt_ex, dat, by = c("Site", "design_link"), 
                      relationship = "many-to-many")
        # Remove unneeded columns unless needed for debugging
        if(!params$debug) {
            message("\tDropping logger/design info columns")
            dat_mrg <- select(dat_mrg, -Table, -loggernet_variable, -design_link, -Logger)
        }
        
        smry_all[[template]] <- data.frame(File = basename(dir_name),
                                           Template = template,
                                           Rows = nrow(dat_mrg),
                                           Note = "")
        
        missing <- anti_join(pt_ex, dat, by = c("Site", "design_link"))
        if(nrow(missing)) {
            dat_issues <<- dat_issues + 1
            message("ERROR: some design links in plot table not found: ", 
                    paste(missing$design_link, collapse = ", "))
            smry_all[[template]]$Note <- "Missing design_link(s)"
            next
        }

        # Put columns in order: first the ones in the template (if available),
        # then TIMESTAMP, research_name, and value; and then any other columns
        # in alphabetized order
        left_cols <- c(base::intersect(colnames(pt_ex), colnames(dat_mrg)), 
                   "research_name", "TIMESTAMP", "value")
        # Note that this order is important, as L1b depends on the fact that
        # everything to the left of TIMESTAMP is a grouping variable
        dat_mrg <- dat_mrg[c(left_cols, sort(setdiff(names(dat_mrg), left_cols)))]
        
        write_to_folders(dat_mrg, root_dir = out_dir, data_level = "L1a",
                         site = dat$Site[1], logger = dat$Logger[1], table = template)
        
    }
    
    return(bind_rows(smry_all))
}

out <- lapply(names(dirs_to_process), f, 
              dirs_to_process = dirs_to_process, out_dir = L1A)
```

## File summary

```{r summary}
#| echo: false
#| output: asis
if(errors) {
    cat("### WARNING: ", errors, " file read/write error(s)\n")
    log_warning(paste("File read/write error(s)", params$html_outfile), 
                logfile = params$logfile)
}
if(dat_issues) {
    cat("### WARNING: ", dat_issues, " data structure issue(s)\n")
    log_warning(paste("data structure issue(s)", params$html_outfile), 
                logfile = params$logfile)
}
```

```{r file_summary_table}
knitr::kable(file_read_smry)
```

## Output summary

```{r output_summary_table}
out_df <- do.call("rbind", out)
knitr::kable(out_df)
```

## Reproducibility

```{r reproducibility}
sessionInfo()
```
